{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Ng'etich.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jane4246/CapsNet-Keras/blob/master/Copy_of_Ng'etich.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFWVZpiQJUDa",
        "outputId": "fb0eb8df-d241-476f-e575-2a678a638f45"
      },
      "source": [
        "#installing the required libraries\n",
        "!pip install keras==2.2.4\n",
        "!pip install tensorflow-gpu==1.14.0\n",
        "!pip install pandas_ml\n",
        "!conda install pandas==0.24.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\r\u001b[K     |█                               | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 20.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 11.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 9.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 92kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 112kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 133kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 163kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 184kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 225kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 245kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 256kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 266kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 276kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 296kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python2.7/dist-packages (from keras==2.2.4) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python2.7/dist-packages (from keras==2.2.4) (1.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from keras==2.2.4) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras==2.2.4) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python2.7/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "Successfully installed keras-2.2.4\n",
            "Collecting tensorflow-gpu==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/6d/2348df00a34baaabdef0fdb4f46f962f7a8a6720362c26c3a44a249767ea/tensorflow_gpu-1.14.0-cp27-cp27mu-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 43kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14.0) (2.0.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14.0) (1.0.8)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/37/e6a7af1c92c5b68fb427f853b06164b56ea92126bcfd87784334ec5e4d42/tensorboard-1.14.0-py2-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 19.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14.0) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14.0) (3.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14.0) (0.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14.0) (0.37.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14.0) (1.16.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14.0) (1.15.0)\n",
            "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14.0) (1.1.10)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14.0) (0.7.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 38.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14.0) (0.1.7)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14.0) (1.0.post1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow-gpu==1.14.0) (3.2.0)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow-gpu==1.14.0) (1.0.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow-gpu==1.14.0) (5.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14.0) (2.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (44.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14.0) (3.1.1)\n",
            "\u001b[31mERROR: tensorflow 2.1.0 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.1.0 has requirement tensorflow-estimator<2.2.0,>=2.1.0rc0, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.1.0\n",
            "    Uninstalling tensorboard-2.1.0:\n",
            "      Successfully uninstalled tensorboard-2.1.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.0\n",
            "    Uninstalling tensorflow-estimator-1.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n",
            "Collecting pandas_ml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/69/f63b234546e39558e8121980daaf7389e52554a608da50005f52dc14f53f/pandas_ml-0.6.1.tar.gz (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.19.0 in /usr/local/lib/python2.7/dist-packages (from pandas_ml) (0.24.2)\n",
            "Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (from pandas_ml) (1.1.10)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python2.7/dist-packages (from pandas>=0.19.0->pandas_ml) (1.16.4)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas>=0.19.0->pandas_ml) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas>=0.19.0->pandas_ml) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas>=0.19.0->pandas_ml) (1.15.0)\n",
            "Building wheels for collected packages: pandas-ml\n",
            "  Building wheel for pandas-ml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-ml: filename=pandas_ml-0.6.1-cp27-none-any.whl size=99435 sha256=038fd6e83a9cd252c054aadb79dff569aac990293d75c470c1ead670f84da8e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/a7/e0/6032cf33b7b780cdfc317752df74d6c0b2ed5a7031ab13f5e9\n",
            "Successfully built pandas-ml\n",
            "Installing collected packages: pandas-ml\n",
            "Successfully installed pandas-ml-0.6.1\n",
            "/bin/bash: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kwh4UHdDJUIJ",
        "outputId": "b952f616-2a71-4672-dadb-b0702c9b3ad9"
      },
      "source": [
        "import sys\n",
        "#!conda install --yes --prefix {sys.prefix} pandas==0.24.2\n",
        "import pandas\n",
        "pandas.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "u'0.24.2'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQjewwJQJUNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bc95f70-2ebb-4f0b-bfa3-604034dec8c0"
      },
      "source": [
        "import numpy as np\n",
        "from keras import layers, models, optimizers\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from utils import combine_images\n",
        "from PIL import Image\n",
        "import pandas\n",
        "from capsulelayers import CapsuleLayer, PrimaryCap, Length, Mask\n",
        "import seaborn as sns\n",
        "from pandas_ml import ConfusionMatrix\n",
        "sns.set()\n",
        "\n",
        "#Required libraries being imported\n",
        "\n",
        "#import tensorflow.keras as kerasfrom __future__ import print_function\n",
        "\n",
        "import keras\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer\n",
        "from keras import activations\n",
        "from keras import utils\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras import optimizers\n",
        "from keras.layers import *\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from os import listdir\n",
        "import os\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "K.set_image_data_format('channels_last')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd0G-7n8JUTN"
      },
      "source": [
        "#Building the CapsNet\n",
        "def CapsNet(input_shape, n_class, routings):\n",
        "    \"\"\"\n",
        "    A Capsule Network on Plantvillage.\n",
        "    :param input_shape: data shape, 3d, [width, height, channels]\n",
        "    :param n_class: number of classes\n",
        "    :param routings: number of routing iterations\n",
        "    :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
        "            `eval_model` can also be used for training.\n",
        "    \"\"\"\n",
        "    x = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Layer 1: Just a conventional Conv2D layer\n",
        "    conv1 = layers.Conv2D(filters=128, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "\n",
        "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
        "    primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
        "\n",
        "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
        "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings,\n",
        "                             name='digitcaps')(primarycaps)\n",
        "\n",
        "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
        "    # If using tensorflow, this will not be necessary. :)\n",
        "    out_caps = Length(name='capsnet')(digitcaps)\n",
        "\n",
        "    # Decoder network.\n",
        "    y = layers.Input(shape=(n_class,))\n",
        "    masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
        "    masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
        "\n",
        "    # Shared Decoder model in training and prediction\n",
        "    decoder = models.Sequential(name='decoder')\n",
        "    decoder.add(layers.Dense(512, activation='relu', input_dim=16*n_class))\n",
        "    decoder.add(layers.Dense(1024, activation='relu'))\n",
        "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
        "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
        "\n",
        "    # Models for training and evaluation (prediction)\n",
        "    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
        "    eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
        "\n",
        "    # manipulate model\n",
        "    noise = layers.Input(shape=(n_class, 16))\n",
        "    noised_digitcaps = layers.Add()([digitcaps, noise])\n",
        "    masked_noised_y = Mask()([noised_digitcaps, y])\n",
        "    manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
        "    return train_model, eval_model, manipulate_model\n",
        "\n",
        "\n",
        "def margin_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
        "    :param y_true: [None, n_classes]\n",
        "    :param y_pred: [None, num_capsule]\n",
        "    :return: a scalar loss value.\n",
        "    \"\"\"\n",
        "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
        "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
        "\n",
        "    return K.mean(K.sum(L, 1))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8tYwM2CJUYd",
        "outputId": "aae98947-f68a-49a5-a04e-d1ffe8505970"
      },
      "source": [
        "#define the model\n",
        "model, eval_model, manipulate_model = CapsNet(input_shape=(28, 28, 3),\n",
        "                                                  n_class=5,\n",
        "                                                  routings=3)\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W1103 08:58:08.163388 139908693211008 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W1103 08:58:08.190578 139908693211008 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W1103 08:58:08.194964 139908693211008 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W1103 08:58:08.320470 139908693211008 deprecation.py:506] From capsulelayers.py:145: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "dim is deprecated, use axis instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 28, 28, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 20, 20, 128)  31232       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_conv2d (Conv2D)      (None, 6, 6, 256)    2654464     conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_reshape (Reshape)    (None, 1152, 8)      0           primarycap_conv2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "primarycap_squash (Lambda)      (None, 1152, 8)      0           primarycap_reshape[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "digitcaps (CapsuleLayer)        (None, 5, 16)        737280      primarycap_squash[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 5)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mask_1 (Mask)                   (None, 80)           0           digitcaps[0][0]                  \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "capsnet (Length)                (None, 5)            0           digitcaps[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "decoder (Sequential)            (None, 28, 28, 3)    2977584     mask_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 6,400,560\n",
            "Trainable params: 6,400,560\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxEXFwNyqc3D",
        "outputId": "f24ce5a0-6bed-4909-c64b-b53ddc4de6d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XcQXINfJUcw",
        "outputId": "b695edbc-81c2-45be-a34c-b187b6f74a56"
      },
      "source": [
        "#Now rewriting the algorithm to preprocess about 500 images in my own pipeline\n",
        "#only do this if you have enough RAM\n",
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None:\n",
        "            image = cv2.resize(image, (28, 28))\n",
        "            return img_to_array(image)\n",
        "        else:\n",
        "            return np.array([])\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(\"Error : {e}\")\n",
        "        return None\n",
        "\n",
        "image_list = []\n",
        "\n",
        "directory_root = '../content/drive/MyDrive/Kahawa'\n",
        "imagePaths = list(paths.list_images(directory_root))\n",
        "imagePaths = imagePaths[0:-1:2]\n",
        "random.shuffle(imagePaths)\n",
        "labels = [p.split(os.path.sep)[-2] for p in imagePaths]\n",
        "\n",
        "batch_size = 16\n",
        "try:\n",
        "    for i in np.arange(0, len(imagePaths), batch_size):\n",
        "        batchPaths = imagePaths[i:i + batch_size]\n",
        "        batchLabels = labels[i: i + batch_size]\n",
        "        \n",
        "        for image in batchPaths:\n",
        "            image_list.append(convert_image_to_array(image))\n",
        "except Exception as e:\n",
        "    print (\"Error: {e}\")\n",
        "\n",
        "\n",
        "len(image_list), len(labels)\n",
        "\n",
        "np_image_list = np.array(image_list, dtype = np.float16) / 255.0\n",
        "print(\"[INFO] splitting data\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, labels, test_size = 0.2, random_state = 42)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] splitting data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59sW27ESJUhb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92370a02-e67c-4360-f4f1-7e94ecddee02"
      },
      "source": [
        "np_image_list.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29275, 28, 28, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRGcrdmBJUlr"
      },
      "source": [
        "y_test_unclassfied = y_test\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGXGoxwfJ_mC"
      },
      "source": [
        "y_test = LabelBinarizer().fit_transform(y_test)\n",
        "y_train = LabelBinarizer().fit_transform(y_train)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A3RZwN6J_rp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11f8c7e9-51a0-4dc5-9a88-af8d8b6b7108"
      },
      "source": [
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "x_train.shape, x_test.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((23420, 28, 28, 3), (5855, 28, 28, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icuzZU8pKIaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f787462-3048-443d-ca11-9625d6ac2b0c"
      },
      "source": [
        "x_train = x_train.reshape((x_train.shape[0], 28, 28, 3))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28, 28, 3))\n",
        "x_train.shape, x_test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((23420, 28, 28, 3), (5855, 28, 28, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsB-0F3uKIke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48af1a9c-2a5d-4f0b-ff4f-730088ed97fb"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5855, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwobKKaLKTSp"
      },
      "source": [
        "x_train.shape, len(y_test)\n",
        "classNames = [str(x) for x in np.unique(labels)]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye8GmumNGd8z"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApqqxUaOKTm6",
        "outputId": "41e8e879-3cd1-4f74-d191-c38ddf8d17ce"
      },
      "source": [
        "#fitting the model\n",
        "model.compile(optimizer=optimizers.Adam(lr=0.001),\n",
        "                  loss=[margin_loss, 'mse'],\n",
        "                  loss_weights=[1., 0.392],\n",
        "                  metrics={'capsnet': 'accuracy'})\n",
        "\n",
        "weight_path = '../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5'\n",
        "checkpoint = ModelCheckpoint(weight_path, monitor='val_capsnet_acc',\n",
        "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
        "history = model.fit([x_train, y_train], [y_train, x_train], validation_data = [[x_test, y_test], [y_test, x_test]], epochs = 50, batch_size = 16, callbacks=[checkpoint])\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W1103 10:22:39.681118 139908693211008 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W1103 10:22:39.941289 139908693211008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1103 10:22:40.615693 139908693211008 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W1103 10:22:40.803852 139908693211008 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 23420 samples, validate on 5855 samples\n",
            "Epoch 1/50\n",
            "23420/23420 [==============================] - 107s 5ms/step - loss: 0.1917 - capsnet_loss: 0.1805 - decoder_loss: 0.0286 - capsnet_acc: 0.7419 - val_loss: 0.1156 - val_capsnet_loss: 0.1070 - val_decoder_loss: 0.0219 - val_capsnet_acc: 0.8606\n",
            "\n",
            "Epoch 00001: val_capsnet_acc improved from -inf to 0.86063, saving model to ../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5\n",
            "Epoch 2/50\n",
            "23420/23420 [==============================] - 98s 4ms/step - loss: 0.1129 - capsnet_loss: 0.1048 - decoder_loss: 0.0205 - capsnet_acc: 0.8672 - val_loss: 0.1209 - val_capsnet_loss: 0.1132 - val_decoder_loss: 0.0197 - val_capsnet_acc: 0.8509\n",
            "\n",
            "Epoch 00002: val_capsnet_acc did not improve from 0.86063\n",
            "Epoch 3/50\n",
            "23420/23420 [==============================] - 101s 4ms/step - loss: 0.0837 - capsnet_loss: 0.0766 - decoder_loss: 0.0181 - capsnet_acc: 0.9134 - val_loss: 0.1029 - val_capsnet_loss: 0.0959 - val_decoder_loss: 0.0179 - val_capsnet_acc: 0.8835\n",
            "\n",
            "Epoch 00003: val_capsnet_acc improved from 0.86063 to 0.88352, saving model to ../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5\n",
            "Epoch 4/50\n",
            "23420/23420 [==============================] - 99s 4ms/step - loss: 0.0665 - capsnet_loss: 0.0601 - decoder_loss: 0.0164 - capsnet_acc: 0.9411 - val_loss: 0.0524 - val_capsnet_loss: 0.0461 - val_decoder_loss: 0.0161 - val_capsnet_acc: 0.9590\n",
            "\n",
            "Epoch 00004: val_capsnet_acc improved from 0.88352 to 0.95901, saving model to ../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5\n",
            "Epoch 5/50\n",
            "23420/23420 [==============================] - 100s 4ms/step - loss: 0.0518 - capsnet_loss: 0.0458 - decoder_loss: 0.0152 - capsnet_acc: 0.9617 - val_loss: 0.0549 - val_capsnet_loss: 0.0487 - val_decoder_loss: 0.0156 - val_capsnet_acc: 0.9392\n",
            "\n",
            "Epoch 00005: val_capsnet_acc did not improve from 0.95901\n",
            "Epoch 6/50\n",
            "23420/23420 [==============================] - 101s 4ms/step - loss: 0.0527 - capsnet_loss: 0.0469 - decoder_loss: 0.0148 - capsnet_acc: 0.9575 - val_loss: 0.0697 - val_capsnet_loss: 0.0637 - val_decoder_loss: 0.0153 - val_capsnet_acc: 0.9457\n",
            "\n",
            "Epoch 00006: val_capsnet_acc did not improve from 0.95901\n",
            "Epoch 7/50\n",
            "23420/23420 [==============================] - 99s 4ms/step - loss: 0.0402 - capsnet_loss: 0.0349 - decoder_loss: 0.0134 - capsnet_acc: 0.9732 - val_loss: 0.0462 - val_capsnet_loss: 0.0407 - val_decoder_loss: 0.0140 - val_capsnet_acc: 0.9646\n",
            "\n",
            "Epoch 00007: val_capsnet_acc improved from 0.95901 to 0.96465, saving model to ../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5\n",
            "Epoch 8/50\n",
            "23420/23420 [==============================] - 98s 4ms/step - loss: 0.0326 - capsnet_loss: 0.0277 - decoder_loss: 0.0126 - capsnet_acc: 0.9814 - val_loss: 0.0244 - val_capsnet_loss: 0.0195 - val_decoder_loss: 0.0125 - val_capsnet_acc: 0.9857\n",
            "\n",
            "Epoch 00008: val_capsnet_acc improved from 0.96465 to 0.98565, saving model to ../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5\n",
            "Epoch 9/50\n",
            "23420/23420 [==============================] - 95s 4ms/step - loss: 0.0280 - capsnet_loss: 0.0234 - decoder_loss: 0.0119 - capsnet_acc: 0.9854 - val_loss: 0.0500 - val_capsnet_loss: 0.0450 - val_decoder_loss: 0.0129 - val_capsnet_acc: 0.9689\n",
            "\n",
            "Epoch 00009: val_capsnet_acc did not improve from 0.98565\n",
            "Epoch 10/50\n",
            "23420/23420 [==============================] - 97s 4ms/step - loss: 0.0224 - capsnet_loss: 0.0180 - decoder_loss: 0.0112 - capsnet_acc: 0.9892 - val_loss: 0.0204 - val_capsnet_loss: 0.0163 - val_decoder_loss: 0.0105 - val_capsnet_acc: 0.9935\n",
            "\n",
            "Epoch 00010: val_capsnet_acc improved from 0.98565 to 0.99351, saving model to ../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5\n",
            "Epoch 11/50\n",
            "23420/23420 [==============================] - 98s 4ms/step - loss: 0.0210 - capsnet_loss: 0.0168 - decoder_loss: 0.0107 - capsnet_acc: 0.9905 - val_loss: 0.0136 - val_capsnet_loss: 0.0096 - val_decoder_loss: 0.0101 - val_capsnet_acc: 0.9942\n",
            "\n",
            "Epoch 00011: val_capsnet_acc improved from 0.99351 to 0.99419, saving model to ../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5\n",
            "Epoch 12/50\n",
            "23420/23420 [==============================] - 98s 4ms/step - loss: 0.0178 - capsnet_loss: 0.0139 - decoder_loss: 0.0099 - capsnet_acc: 0.9927 - val_loss: 0.0112 - val_capsnet_loss: 0.0076 - val_decoder_loss: 0.0092 - val_capsnet_acc: 0.9950\n",
            "\n",
            "Epoch 00012: val_capsnet_acc improved from 0.99419 to 0.99505, saving model to ../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5\n",
            "Epoch 13/50\n",
            "23420/23420 [==============================] - 101s 4ms/step - loss: 0.0158 - capsnet_loss: 0.0121 - decoder_loss: 0.0094 - capsnet_acc: 0.9942 - val_loss: 0.0094 - val_capsnet_loss: 0.0060 - val_decoder_loss: 0.0087 - val_capsnet_acc: 0.9968\n",
            "\n",
            "Epoch 00013: val_capsnet_acc improved from 0.99505 to 0.99675, saving model to ../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5\n",
            "Epoch 14/50\n",
            "23420/23420 [==============================] - 98s 4ms/step - loss: 0.0146 - capsnet_loss: 0.0111 - decoder_loss: 0.0089 - capsnet_acc: 0.9944 - val_loss: 0.0080 - val_capsnet_loss: 0.0047 - val_decoder_loss: 0.0082 - val_capsnet_acc: 0.9976\n",
            "\n",
            "Epoch 00014: val_capsnet_acc improved from 0.99675 to 0.99761, saving model to ../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5\n",
            "Epoch 15/50\n",
            "23420/23420 [==============================] - 100s 4ms/step - loss: 0.0126 - capsnet_loss: 0.0093 - decoder_loss: 0.0084 - capsnet_acc: 0.9958 - val_loss: 0.0148 - val_capsnet_loss: 0.0112 - val_decoder_loss: 0.0092 - val_capsnet_acc: 0.9968\n",
            "\n",
            "Epoch 00015: val_capsnet_acc did not improve from 0.99761\n",
            "Epoch 16/50\n",
            "23420/23420 [==============================] - 98s 4ms/step - loss: 0.0141 - capsnet_loss: 0.0108 - decoder_loss: 0.0084 - capsnet_acc: 0.9949 - val_loss: 0.0087 - val_capsnet_loss: 0.0054 - val_decoder_loss: 0.0085 - val_capsnet_acc: 0.9978\n",
            "\n",
            "Epoch 00016: val_capsnet_acc improved from 0.99761 to 0.99778, saving model to ../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5\n",
            "Epoch 17/50\n",
            "23420/23420 [==============================] - 98s 4ms/step - loss: 0.0132 - capsnet_loss: 0.0101 - decoder_loss: 0.0080 - capsnet_acc: 0.9944 - val_loss: 0.0059 - val_capsnet_loss: 0.0032 - val_decoder_loss: 0.0069 - val_capsnet_acc: 0.9980\n",
            "\n",
            "Epoch 00017: val_capsnet_acc improved from 0.99778 to 0.99795, saving model to ../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5\n",
            "Epoch 18/50\n",
            "23420/23420 [==============================] - 99s 4ms/step - loss: 0.0086 - capsnet_loss: 0.0059 - decoder_loss: 0.0069 - capsnet_acc: 0.9977 - val_loss: 0.1248 - val_capsnet_loss: 0.1155 - val_decoder_loss: 0.0238 - val_capsnet_acc: 0.8796\n",
            "\n",
            "Epoch 00018: val_capsnet_acc did not improve from 0.99795\n",
            "Epoch 19/50\n",
            "23420/23420 [==============================] - 95s 4ms/step - loss: 0.0109 - capsnet_loss: 0.0081 - decoder_loss: 0.0072 - capsnet_acc: 0.9955 - val_loss: 0.0123 - val_capsnet_loss: 0.0093 - val_decoder_loss: 0.0076 - val_capsnet_acc: 0.9971\n",
            "\n",
            "Epoch 00019: val_capsnet_acc did not improve from 0.99795\n",
            "Epoch 20/50\n",
            "23420/23420 [==============================] - 98s 4ms/step - loss: 0.0098 - capsnet_loss: 0.0070 - decoder_loss: 0.0069 - capsnet_acc: 0.9973 - val_loss: 0.0047 - val_capsnet_loss: 0.0022 - val_decoder_loss: 0.0065 - val_capsnet_acc: 0.9986\n",
            "\n",
            "Epoch 00020: val_capsnet_acc improved from 0.99795 to 0.99863, saving model to ../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5\n",
            "Epoch 21/50\n",
            "23420/23420 [==============================] - 96s 4ms/step - loss: 0.0127 - capsnet_loss: 0.0101 - decoder_loss: 0.0068 - capsnet_acc: 0.9939 - val_loss: 0.0039 - val_capsnet_loss: 0.0015 - val_decoder_loss: 0.0060 - val_capsnet_acc: 0.9986\n",
            "\n",
            "Epoch 00021: val_capsnet_acc did not improve from 0.99863\n",
            "Epoch 22/50\n",
            "23420/23420 [==============================] - 97s 4ms/step - loss: 0.0094 - capsnet_loss: 0.0070 - decoder_loss: 0.0061 - capsnet_acc: 0.9959 - val_loss: 0.0080 - val_capsnet_loss: 0.0053 - val_decoder_loss: 0.0069 - val_capsnet_acc: 0.9985\n",
            "\n",
            "Epoch 00022: val_capsnet_acc did not improve from 0.99863\n",
            "Epoch 23/50\n",
            "23420/23420 [==============================] - 99s 4ms/step - loss: 0.0110 - capsnet_loss: 0.0084 - decoder_loss: 0.0066 - capsnet_acc: 0.9959 - val_loss: 0.0046 - val_capsnet_loss: 0.0023 - val_decoder_loss: 0.0058 - val_capsnet_acc: 0.9985\n",
            "\n",
            "Epoch 00023: val_capsnet_acc did not improve from 0.99863\n",
            "Epoch 24/50\n",
            "23420/23420 [==============================] - 98s 4ms/step - loss: 0.0066 - capsnet_loss: 0.0045 - decoder_loss: 0.0054 - capsnet_acc: 0.9979 - val_loss: 0.0300 - val_capsnet_loss: 0.0259 - val_decoder_loss: 0.0104 - val_capsnet_acc: 0.9797\n",
            "\n",
            "Epoch 00024: val_capsnet_acc did not improve from 0.99863\n",
            "Epoch 25/50\n",
            "23420/23420 [==============================] - 102s 4ms/step - loss: 0.0061 - capsnet_loss: 0.0039 - decoder_loss: 0.0056 - capsnet_acc: 0.9985 - val_loss: 0.0037 - val_capsnet_loss: 0.0018 - val_decoder_loss: 0.0049 - val_capsnet_acc: 0.9990\n",
            "\n",
            "Epoch 00025: val_capsnet_acc improved from 0.99863 to 0.99898, saving model to ../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5\n",
            "Epoch 26/50\n",
            "23420/23420 [==============================] - 97s 4ms/step - loss: 0.0130 - capsnet_loss: 0.0106 - decoder_loss: 0.0062 - capsnet_acc: 0.9944 - val_loss: 0.0175 - val_capsnet_loss: 0.0140 - val_decoder_loss: 0.0087 - val_capsnet_acc: 0.9959\n",
            "\n",
            "Epoch 00026: val_capsnet_acc did not improve from 0.99898\n",
            "Epoch 27/50\n",
            "23420/23420 [==============================] - 100s 4ms/step - loss: 0.0059 - capsnet_loss: 0.0038 - decoder_loss: 0.0053 - capsnet_acc: 0.9987 - val_loss: 0.0060 - val_capsnet_loss: 0.0037 - val_decoder_loss: 0.0059 - val_capsnet_acc: 0.9986\n",
            "\n",
            "Epoch 00027: val_capsnet_acc did not improve from 0.99898\n",
            "Epoch 28/50\n",
            "23420/23420 [==============================] - 99s 4ms/step - loss: 0.0053 - capsnet_loss: 0.0034 - decoder_loss: 0.0050 - capsnet_acc: 0.9984 - val_loss: 0.0025 - val_capsnet_loss: 8.7823e-04 - val_decoder_loss: 0.0043 - val_capsnet_acc: 0.9990\n",
            "\n",
            "Epoch 00028: val_capsnet_acc did not improve from 0.99898\n",
            "Epoch 29/50\n",
            "23420/23420 [==============================] - 98s 4ms/step - loss: 0.0074 - capsnet_loss: 0.0053 - decoder_loss: 0.0052 - capsnet_acc: 0.9976 - val_loss: 0.0027 - val_capsnet_loss: 0.0010 - val_decoder_loss: 0.0042 - val_capsnet_acc: 0.9991\n",
            "\n",
            "Epoch 00029: val_capsnet_acc improved from 0.99898 to 0.99915, saving model to ../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5\n",
            "Epoch 30/50\n",
            "23420/23420 [==============================] - 100s 4ms/step - loss: 0.0118 - capsnet_loss: 0.0096 - decoder_loss: 0.0056 - capsnet_acc: 0.9927 - val_loss: 0.0029 - val_capsnet_loss: 0.0012 - val_decoder_loss: 0.0045 - val_capsnet_acc: 0.9990\n",
            "\n",
            "Epoch 00030: val_capsnet_acc did not improve from 0.99915\n",
            "Epoch 31/50\n",
            "23420/23420 [==============================] - 98s 4ms/step - loss: 0.0088 - capsnet_loss: 0.0067 - decoder_loss: 0.0053 - capsnet_acc: 0.9966 - val_loss: 0.0039 - val_capsnet_loss: 0.0020 - val_decoder_loss: 0.0048 - val_capsnet_acc: 0.9990\n",
            "\n",
            "Epoch 00031: val_capsnet_acc did not improve from 0.99915\n",
            "Epoch 32/50\n",
            "23420/23420 [==============================] - 102s 4ms/step - loss: 0.0019 - capsnet_loss: 4.9743e-04 - decoder_loss: 0.0037 - capsnet_acc: 1.0000 - val_loss: 0.0039 - val_capsnet_loss: 0.0021 - val_decoder_loss: 0.0047 - val_capsnet_acc: 0.9990\n",
            "\n",
            "Epoch 00032: val_capsnet_acc did not improve from 0.99915\n",
            "Epoch 33/50\n",
            "23420/23420 [==============================] - 99s 4ms/step - loss: 0.0110 - capsnet_loss: 0.0089 - decoder_loss: 0.0055 - capsnet_acc: 0.9942 - val_loss: 0.0021 - val_capsnet_loss: 6.2929e-04 - val_decoder_loss: 0.0038 - val_capsnet_acc: 0.9991\n",
            "\n",
            "Epoch 00033: val_capsnet_acc did not improve from 0.99915\n",
            "Epoch 34/50\n",
            "23420/23420 [==============================] - 101s 4ms/step - loss: 0.0058 - capsnet_loss: 0.0041 - decoder_loss: 0.0043 - capsnet_acc: 0.9981 - val_loss: 0.0046 - val_capsnet_loss: 0.0028 - val_decoder_loss: 0.0046 - val_capsnet_acc: 0.9995\n",
            "\n",
            "Epoch 00034: val_capsnet_acc improved from 0.99915 to 0.99949, saving model to ../content/drive/MyDrive/Models for Goz project/best_weights_capsule_new_train.h5\n",
            "Epoch 35/50\n",
            "23420/23420 [==============================] - 104s 4ms/step - loss: 0.0074 - capsnet_loss: 0.0054 - decoder_loss: 0.0050 - capsnet_acc: 0.9977 - val_loss: 0.0052 - val_capsnet_loss: 0.0031 - val_decoder_loss: 0.0054 - val_capsnet_acc: 0.9991\n",
            "\n",
            "Epoch 00035: val_capsnet_acc did not improve from 0.99949\n",
            "Epoch 36/50\n",
            "23420/23420 [==============================] - 99s 4ms/step - loss: 0.0224 - capsnet_loss: 0.0202 - decoder_loss: 0.0056 - capsnet_acc: 0.9745 - val_loss: 0.2906 - val_capsnet_loss: 0.2767 - val_decoder_loss: 0.0354 - val_capsnet_acc: 0.5927\n",
            "\n",
            "Epoch 00036: val_capsnet_acc did not improve from 0.99949\n",
            "Epoch 37/50\n",
            "23420/23420 [==============================] - 104s 4ms/step - loss: 0.0678 - capsnet_loss: 0.0611 - decoder_loss: 0.0172 - capsnet_acc: 0.9334 - val_loss: 0.0326 - val_capsnet_loss: 0.0266 - val_decoder_loss: 0.0153 - val_capsnet_acc: 0.9783\n",
            "\n",
            "Epoch 00037: val_capsnet_acc did not improve from 0.99949\n",
            "Epoch 38/50\n",
            "23420/23420 [==============================] - 101s 4ms/step - loss: 0.0303 - capsnet_loss: 0.0257 - decoder_loss: 0.0117 - capsnet_acc: 0.9786 - val_loss: 0.0207 - val_capsnet_loss: 0.0164 - val_decoder_loss: 0.0110 - val_capsnet_acc: 0.9904\n",
            "\n",
            "Epoch 00038: val_capsnet_acc did not improve from 0.99949\n",
            "Epoch 39/50\n",
            "23420/23420 [==============================] - 102s 4ms/step - loss: 0.0212 - capsnet_loss: 0.0173 - decoder_loss: 0.0100 - capsnet_acc: 0.9879 - val_loss: 0.0133 - val_capsnet_loss: 0.0097 - val_decoder_loss: 0.0093 - val_capsnet_acc: 0.9932\n",
            "\n",
            "Epoch 00039: val_capsnet_acc did not improve from 0.99949\n",
            "Epoch 40/50\n",
            "23420/23420 [==============================] - 102s 4ms/step - loss: 0.0188 - capsnet_loss: 0.0152 - decoder_loss: 0.0091 - capsnet_acc: 0.9890 - val_loss: 0.0122 - val_capsnet_loss: 0.0087 - val_decoder_loss: 0.0088 - val_capsnet_acc: 0.9927\n",
            "\n",
            "Epoch 00040: val_capsnet_acc did not improve from 0.99949\n",
            "Epoch 41/50\n",
            "23420/23420 [==============================] - 100s 4ms/step - loss: 0.0159 - capsnet_loss: 0.0126 - decoder_loss: 0.0085 - capsnet_acc: 0.9918 - val_loss: 0.0158 - val_capsnet_loss: 0.0122 - val_decoder_loss: 0.0093 - val_capsnet_acc: 0.9944\n",
            "\n",
            "Epoch 00041: val_capsnet_acc did not improve from 0.99949\n",
            "Epoch 42/50\n",
            "23420/23420 [==============================] - 103s 4ms/step - loss: 0.0124 - capsnet_loss: 0.0094 - decoder_loss: 0.0076 - capsnet_acc: 0.9942 - val_loss: 0.0101 - val_capsnet_loss: 0.0069 - val_decoder_loss: 0.0082 - val_capsnet_acc: 0.9957\n",
            "\n",
            "Epoch 00042: val_capsnet_acc did not improve from 0.99949\n",
            "Epoch 43/50\n",
            "23420/23420 [==============================] - 100s 4ms/step - loss: 0.0120 - capsnet_loss: 0.0091 - decoder_loss: 0.0073 - capsnet_acc: 0.9944 - val_loss: 0.0073 - val_capsnet_loss: 0.0046 - val_decoder_loss: 0.0069 - val_capsnet_acc: 0.9968\n",
            "\n",
            "Epoch 00043: val_capsnet_acc did not improve from 0.99949\n",
            "Epoch 44/50\n",
            "23420/23420 [==============================] - 104s 4ms/step - loss: 0.0125 - capsnet_loss: 0.0097 - decoder_loss: 0.0070 - capsnet_acc: 0.9935 - val_loss: 0.0058 - val_capsnet_loss: 0.0034 - val_decoder_loss: 0.0062 - val_capsnet_acc: 0.9976\n",
            "\n",
            "Epoch 00044: val_capsnet_acc did not improve from 0.99949\n",
            "Epoch 45/50\n",
            "23420/23420 [==============================] - 100s 4ms/step - loss: 0.0115 - capsnet_loss: 0.0089 - decoder_loss: 0.0066 - capsnet_acc: 0.9941 - val_loss: 0.0060 - val_capsnet_loss: 0.0036 - val_decoder_loss: 0.0062 - val_capsnet_acc: 0.9978\n",
            "\n",
            "Epoch 00045: val_capsnet_acc did not improve from 0.99949\n",
            "Epoch 46/50\n",
            "23420/23420 [==============================] - 101s 4ms/step - loss: 0.0121 - capsnet_loss: 0.0095 - decoder_loss: 0.0065 - capsnet_acc: 0.9930 - val_loss: 0.0055 - val_capsnet_loss: 0.0032 - val_decoder_loss: 0.0059 - val_capsnet_acc: 0.9978\n",
            "\n",
            "Epoch 00046: val_capsnet_acc did not improve from 0.99949\n",
            "Epoch 47/50\n",
            "23420/23420 [==============================] - 102s 4ms/step - loss: 0.0098 - capsnet_loss: 0.0075 - decoder_loss: 0.0059 - capsnet_acc: 0.9949 - val_loss: 0.0050 - val_capsnet_loss: 0.0029 - val_decoder_loss: 0.0054 - val_capsnet_acc: 0.9976\n",
            "\n",
            "Epoch 00047: val_capsnet_acc did not improve from 0.99949\n",
            "Epoch 48/50\n",
            "23420/23420 [==============================] - 101s 4ms/step - loss: 0.0140 - capsnet_loss: 0.0116 - decoder_loss: 0.0060 - capsnet_acc: 0.9902 - val_loss: 0.0046 - val_capsnet_loss: 0.0027 - val_decoder_loss: 0.0050 - val_capsnet_acc: 0.9973\n",
            "\n",
            "Epoch 00048: val_capsnet_acc did not improve from 0.99949\n",
            "Epoch 49/50\n",
            "23420/23420 [==============================] - 103s 4ms/step - loss: 0.0115 - capsnet_loss: 0.0091 - decoder_loss: 0.0060 - capsnet_acc: 0.9941 - val_loss: 0.0313 - val_capsnet_loss: 0.0281 - val_decoder_loss: 0.0082 - val_capsnet_acc: 0.9752\n",
            "\n",
            "Epoch 00049: val_capsnet_acc did not improve from 0.99949\n",
            "Epoch 50/50\n",
            "23420/23420 [==============================] - 100s 4ms/step - loss: 0.0080 - capsnet_loss: 0.0059 - decoder_loss: 0.0053 - capsnet_acc: 0.9959 - val_loss: 0.0120 - val_capsnet_loss: 0.0091 - val_decoder_loss: 0.0074 - val_capsnet_acc: 0.9952\n",
            "\n",
            "Epoch 00050: val_capsnet_acc did not improve from 0.99949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgtZs-9rJUqx"
      },
      "source": [
        "acc = model.history.history['capsnet_acc']\n",
        "val_acc = model.history.history['val_capsnet_acc']\n",
        "loss = model.history.history['capsnet_loss']\n",
        "val_loss = model.history.history['val_capsnet_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "\n",
        "#accuracy plot\n",
        "plt.plot(epochs, acc, color='green', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, color='blue', label='Testing Accuracy')\n",
        "plt.title('Training and Testing Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.savefig('./content/drive/MyDrive/jane_leaf/code/Plots/Accuracy_Capsulenet_Colored.png')\n",
        "plt.show()\n",
        "plt.clf()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLadCeVSRV04"
      },
      "source": [
        "#loss plot\n",
        "plt.plot(epochs, loss, color='blue', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, color='red', label='Testing Loss')\n",
        "plt.title('Training and Testing Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig(\".../content/drive/MyDrive/jane_leaf/code/Plots/Loss_Capsulenet_Colored.png\")\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmcNXc3nNdIC"
      },
      "source": [
        "#import the weights from saved\n",
        "eval_model.load_weights('../content/drive/My Drive/Models for Goz project/best_weights_capsule_new_train.h5')\n",
        "y_pred = []\n",
        "for i in range(0, x_test.shape[0]):\n",
        "    img = np.expand_dims(x_test[i], axis=0)\n",
        "    prediction, y_recon = eval_model.predict(img)\n",
        "    li = [\"Cerscospora\", \"Healthy\",\"Leaf rust\",\"Miner\", \"Phoma\"] \n",
        "    class_name = li[prediction.argmax()]\n",
        "    y_pred.append(class_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXwkojPYNha6",
        "outputId": "16c7ef7c-93e0-4373-b107-992e9bb58039"
      },
      "source": [
        "len(y_test_unclassfied) == len(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvswEVwqNkCD"
      },
      "source": [
        "#plotting the confusion matrix and evaluating the predictions\n",
        "confusion_matrix = ConfusionMatrix(y_test_unclassfied, y_pred)\n",
        "print(\"Confusion matrix:\\n%s\" % confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N9lTSLSNojy"
      },
      "source": [
        "confusion_matrix.print_stats()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cPo6M1RNyxo"
      },
      "source": [
        "confusion_matrix.to_dataframe().to_csv('.../Results')\n",
        "confusion_matrix.to_dataframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F78VvW0eOITc"
      },
      "source": [
        "confusion_matrix.stats_class.to_csv(\"./content/drive/My Drive/jane_leaf/code/Results/confusion_matrix_colored_resized.csv\")\n",
        "confusion_matrix.stats_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxU8Wx0NOJ4w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}